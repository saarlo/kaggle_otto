{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XBOOST_LOCATION = '/Users/siim/Lib/xgboost/wrapper'\n",
    "import sys\n",
    "sys.path.append(XBOOST_LOCATION)\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportional_train_test_split(df, label_col, test_size=0.25):\n",
    "    '''\n",
    "    split dataframe into training and test set so that label proportions stay the same \n",
    "    @param df DataFrame input data\n",
    "    @param label_col String name of column that holds class labels\n",
    "    @test_size float proportion of test set in range (0,1)\n",
    "    '''   \n",
    "    label_col = 'target'\n",
    "    labels = df[label_col].unique()   \n",
    "    \n",
    "    train_arrays, test_arrays = [], []    \n",
    "    for label in labels:\n",
    "        arr1, arr2 = train_test_split(df[df[label_col] == label], test_size=test_size)\n",
    "        train_arrays.append(arr1)\n",
    "        test_arrays.append(arr2)        \n",
    "        \n",
    "    return pd.DataFrame(np.concatenate(train_arrays), columns=df.columns), \\\n",
    "            pd.DataFrame(np.concatenate(test_arrays), columns=df.columns)\n",
    "    \n",
    "    \n",
    "# read data from csv to DataFrames\n",
    "df = pd.read_csv('./train.csv', index_col=0)\n",
    "df_train, df_control = proportional_train_test_split(df, 'target', test_size=0.2)\n",
    "\n",
    "label_train = df_train.target.values\n",
    "df_train = df_train.drop('target', axis=1)\n",
    "label_control = df_control.target.values\n",
    "df_control = df_control.drop('target', axis=1)\n",
    "\n",
    "label_all = df.target.values\n",
    "df = df.drop('target', axis=1)\n",
    "\n",
    "df_test = pd.read_csv('./test.csv', index_col=0)\n",
    "\n",
    "\n",
    "# create xgboost data structures\n",
    "labels = [int(x.split('_')[1]) - 1 for x in label_train]\n",
    "dtrain = xgb.DMatrix(df_train.values, label=labels)\n",
    "\n",
    "labels = [int(x.split('_')[1]) - 1 for x in label_control]\n",
    "dcontrol = xgb.DMatrix(df_control.values, label=labels)\n",
    "\n",
    "labels = [int(x.split('_')[1]) - 1 for x in label_all]\n",
    "dall = xgb.DMatrix(df.values, label=labels) \n",
    "\n",
    "dtest = xgb.DMatrix(df_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 0.1, 1, 10, 0.01, False) (4, 2.144435)\n",
      "(0.1, 0.1, 1, 10, 0.01, 0.2) (4, 2.14441)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "'''\n",
    "Grid search. Define param_options and for-loop below performs \n",
    "grid search over all possible combinations\n",
    "printing out best mean test logloss score for each\n",
    "\n",
    "When running through many options, then put output to DataFrame, \n",
    "group by different columns and aggregate to find best settings\n",
    "'''\n",
    "\n",
    "from operator import itemgetter\n",
    "def best_cv_result(cv_results):\n",
    "    '''get number of round and mean score for best result by test folds'''\n",
    "    aux = [float( x.split(':')[1].split('+')[0] ) for x in cv_results] \n",
    "    return min(enumerate( aux ), key=itemgetter(1) )\n",
    "\n",
    "param_initial = {\n",
    "        'silent': 0,\n",
    "        'objective': 'multi:softprob', \n",
    "        'num_class': 9,\n",
    "        'eval_metric': 'mlogloss'\n",
    "    }\n",
    "\n",
    "param_options = (\n",
    "        ('subsample', [0.1]),\n",
    "        ('colsample_bytree', [0.1]),\n",
    "        ('min_child_weight', [1]),\n",
    "        ('max_depth', [10]),\n",
    "        ('eta', [0.01]),\n",
    "        ('gamma', [False, 0.2])\n",
    "    )\n",
    "\n",
    "num_round = 5\n",
    "nfold = 5\n",
    "\n",
    "for param_vals in itertools.product(*[aux[1] for aux in param_options]):\n",
    "        \n",
    "    param = param_initial\n",
    "    for i, val in enumerate(param_vals):\n",
    "        if val is not False:\n",
    "            param[param_options[i][0]] = val\n",
    "        \n",
    "    cv_results = xgb.cv(param, dtrain, num_round, nfold=nfold)\n",
    "    print param_vals, best_cv_result(cv_results)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 {'bst:max_depth': 10, 'subsample': 0.1, 'bst:eta': 0.1, 'gamma': 0.1, 'num_class': 9, 'silent': 0, 'eval_metric': 'mlogloss', 'objective': 'multi:softprob', 'colsample_bytree': 0.1, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "use parameters found from grid search above\n",
    "'''\n",
    "with_train_test_split = False\n",
    "run_prediction = False\n",
    "\n",
    "param = {\n",
    "    'silent': 0,\n",
    "    'objective': 'multi:softprob', \n",
    "    'num_class': 9,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'subsample': 0.1,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'min_child_weight': 1,\n",
    "    'bst:max_depth':10,\n",
    "    'bst:eta': 0.1,\n",
    "    'gamma': 0.1\n",
    "}\n",
    "num_round = 4200\n",
    "\n",
    "print num_round, param\n",
    "\n",
    "plst = param.items()\n",
    "\n",
    "if with_train_test_split:\n",
    "    evallist = [(dcontrol,'eval'), (dtrain,'train')]\n",
    "    bst = xgb.train( plst, dtrain, num_round, evallist )\n",
    "else: \n",
    "    evallist = [(dall,'train')]\n",
    "    bst = xgb.train( plst, dall, num_round, evallist )\n",
    "    \n",
    "if run_prediction:\n",
    "    pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "label_columns = ['Class_' + str(i) for i in range(1,10)]\n",
    "with open('./output.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh)\n",
    "    writer.writerow(['id'] + label_columns)\n",
    "    for i, r in enumerate(pred):\n",
    "        row = [i+1] + map(lambda x: round(x, 3), list(r))\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
